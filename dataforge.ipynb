{"cells":[{"cell_type":"markdown","metadata":{},"source":["## This is a prototype based on a book.\n","### Used class-6th science ncert for this."]},{"cell_type":"markdown","metadata":{},"source":["### Required libraries "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:28:37.645082Z","iopub.status.busy":"2026-01-11T10:28:37.644862Z","iopub.status.idle":"2026-01-11T10:28:41.505279Z","shell.execute_reply":"2026-01-11T10:28:41.504466Z","shell.execute_reply.started":"2026-01-11T10:28:37.645058Z"},"trusted":true},"outputs":[],"source":["!pip install -q \\\n","    langchain langchain-community langchain-core \\\n","    langchain-cohere cohere \\\n","    faiss-cpu sentence-transformers \\\n","    tiktoken python-dotenv\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:28:41.507348Z","iopub.status.busy":"2026-01-11T10:28:41.507071Z","iopub.status.idle":"2026-01-11T10:28:44.618815Z","shell.execute_reply":"2026-01-11T10:28:44.617899Z","shell.execute_reply.started":"2026-01-11T10:28:41.507319Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pyvis in /usr/local/lib/python3.12/dist-packages (0.3.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.5)\n","Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from pyvis) (7.34.0)\n","Requirement already satisfied: jinja2>=2.9.6 in /usr/local/lib/python3.12/dist-packages (from pyvis) (3.1.6)\n","Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from pyvis) (4.1.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (75.2.0)\n","Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.19.2)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.7.5)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (3.0.52)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (2.19.2)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (0.1.7)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=5.3.0->pyvis) (4.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.9.6->pyvis) (3.0.3)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.5)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.3.0->pyvis) (0.2.14)\n"]}],"source":["!pip install pyvis networkx\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:28:44.620308Z","iopub.status.busy":"2026-01-11T10:28:44.620049Z","iopub.status.idle":"2026-01-11T10:28:48.906947Z","shell.execute_reply":"2026-01-11T10:28:48.906222Z","shell.execute_reply.started":"2026-01-11T10:28:44.620279Z"},"trusted":true},"outputs":[],"source":["from langchain_community.document_loaders import TextLoader\n","from langchain.document_loaders import PyPDFLoader\n","from langchain.text_splitter import RecursiveCharacterTextSplitter\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_community.vectorstores import FAISS\n","from langchain_core.prompts import PromptTemplate\n","from langchain_cohere import ChatCohere\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.output_parsers import StrOutputParser\n","import os\n"]},{"cell_type":"markdown","metadata":{},"source":["### api key for LLM"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:28:48.909202Z","iopub.status.busy":"2026-01-11T10:28:48.908830Z","iopub.status.idle":"2026-01-11T10:28:48.912619Z","shell.execute_reply":"2026-01-11T10:28:48.911975Z","shell.execute_reply.started":"2026-01-11T10:28:48.909179Z"},"trusted":true},"outputs":[],"source":["os.environ['cohere_api_key'] = \"API KEY\""]},{"cell_type":"markdown","metadata":{},"source":["### creating vector store"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:28:48.913867Z","iopub.status.busy":"2026-01-11T10:28:48.913547Z","iopub.status.idle":"2026-01-11T10:29:06.607393Z","shell.execute_reply":"2026-01-11T10:29:06.606697Z","shell.execute_reply.started":"2026-01-11T10:28:48.913833Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_368/3775585463.py:16: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n","  embeddings = HuggingFaceEmbeddings(model_name=model_name)\n","2026-01-11 10:28:58.843672: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","E0000 00:00:1768127338.864964     368 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","E0000 00:00:1768127338.871449     368 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","W0000 00:00:1768127338.888297     368 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1768127338.888321     368 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1768127338.888324     368 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","W0000 00:00:1768127338.888326     368 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"]}],"source":["file_path = \"/kaggle/input/scinceclass6/science class 6.pdf\"\n","\n","loader = PyPDFLoader(file_path)\n","documents = loader.load()\n","\n","chunk_size = 50  \n","chunk_overlap = 5\n","\n","text_splitter = RecursiveCharacterTextSplitter(\n","    chunk_size=chunk_size,\n","    chunk_overlap=chunk_overlap,\n",")\n","all_splits = text_splitter.split_documents(documents)\n","\n","model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n","embeddings = HuggingFaceEmbeddings(model_name=model_name)\n","vectorstore = FAISS.from_documents(all_splits, embedding = embeddings) \n","\n","retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 25})"]},{"cell_type":"markdown","metadata":{},"source":["### prompts"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:30:15.476154Z","iopub.status.busy":"2026-01-11T10:30:15.475466Z","iopub.status.idle":"2026-01-11T10:30:15.480426Z","shell.execute_reply":"2026-01-11T10:30:15.479655Z","shell.execute_reply.started":"2026-01-11T10:30:15.476111Z"},"trusted":true},"outputs":[],"source":["prompt_template = \"\"\"\n","You are a helpful assistant answering questions from the Class 6 NCERT Science textbook.\n","\n","Instructions:\n","1. Use the Context and the Knowledge Graph to answer the Question.\n","2. Do NOT use outside knowledge.\n","3. If the Context is completely unrelated, say:\n","   \"The answer is not present in the provided text.\"\n","4. Write the answer in simple language suitable for a Class 6 student.\n","\n","Context:\n","{context}\n","\n","Knowledge Graph:\n","{kg}\n","\n","Question:\n","{question}\n","\n","Answer:\n","\"\"\"\n","\n","kg_prompt_template = \"\"\"\n","You are given text from a Class 6 NCERT Science textbook.\n","\n","Task:\n","Extract important entities and relationships from the text.\n","\n","Rules:\n","- Use only the given text.\n","- Keep entities simple and relevant.\n","- Relations should be short and clear.\n","- Do not add outside knowledge.\n","\n","Output format (strict):\n","Entities:\n","- Entity 1\n","- Entity 2\n","\n","Relations:\n","- Entity 1 -> relation -> Entity 2\n","\n","Text:\n","{text}\n","\"\"\"\n","\n","\n","\n","prompt = PromptTemplate.from_template(template=prompt_template)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:29:06.614811Z","iopub.status.busy":"2026-01-11T10:29:06.614447Z","iopub.status.idle":"2026-01-11T10:29:06.638443Z","shell.execute_reply":"2026-01-11T10:29:06.637836Z","shell.execute_reply.started":"2026-01-11T10:29:06.614774Z"},"trusted":true},"outputs":[],"source":["def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:29:06.639786Z","iopub.status.busy":"2026-01-11T10:29:06.639459Z","iopub.status.idle":"2026-01-11T10:29:06.655628Z","shell.execute_reply":"2026-01-11T10:29:06.655039Z","shell.execute_reply.started":"2026-01-11T10:29:06.639734Z"},"trusted":true},"outputs":[],"source":["def extract_kg(docs):\n","    cohere_llm = ChatCohere(\n","        model=\"command-xlarge-nightly\",\n","        temperature=0.0,\n","        cohere_api_key=os.getenv(\"cohere_api_key\")\n","    )\n","\n","    kg_prompt = PromptTemplate(\n","        input_variables=[\"text\"],\n","        template=kg_prompt_template\n","    )\n","\n","    context_text = \"\\n\".join(doc.page_content for doc in docs)\n","\n","    kg_chain = kg_prompt | cohere_llm | StrOutputParser()\n","\n","    return kg_chain.invoke({\"text\": context_text})\n"]},{"cell_type":"markdown","metadata":{},"source":["### for KG visualisation "]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:29:06.656697Z","iopub.status.busy":"2026-01-11T10:29:06.656472Z","iopub.status.idle":"2026-01-11T10:29:06.672685Z","shell.execute_reply":"2026-01-11T10:29:06.672153Z","shell.execute_reply.started":"2026-01-11T10:29:06.656675Z"},"trusted":true},"outputs":[],"source":["import re\n","\n","def parse_kg(kg_text):\n","    entities = set()\n","    edges = []\n","\n","    in_entities = False\n","    in_relations = False\n","\n","    for line in kg_text.split(\"\\n\"):\n","        line = line.strip()\n","\n","        if line.lower().startswith(\"entities\"):\n","            in_entities = True\n","            in_relations = False\n","            continue\n","\n","        if line.lower().startswith(\"relations\"):\n","            in_entities = False\n","            in_relations = True\n","            continue\n","\n","        if line.startswith(\"-\"):\n","            content = line[1:].strip()\n","\n","            if in_entities:\n","                entities.add(content)\n","\n","            elif in_relations and \"->\" in content:\n","                src, rel, tgt = [p.strip() for p in content.split(\"->\")]\n","                entities.add(src)\n","                entities.add(tgt)\n","                edges.append((src, rel, tgt))\n","\n","    return list(entities), edges\n","\n","\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:29:06.674994Z","iopub.status.busy":"2026-01-11T10:29:06.674677Z","iopub.status.idle":"2026-01-11T10:29:06.887056Z","shell.execute_reply":"2026-01-11T10:29:06.886469Z","shell.execute_reply.started":"2026-01-11T10:29:06.674971Z"},"trusted":true},"outputs":[],"source":["from pyvis.network import Network\n","\n","def visualize_kg(kg_text, output_file=\"kg.html\"):\n","    entities, edges = parse_kg(kg_text)\n","\n","    net = Network(\n","        height=\"600px\",\n","        width=\"100%\",\n","        directed=True,\n","        bgcolor=\"#ffffff\",\n","        font_color=\"black\"\n","    )\n","\n","    # Better physics for separation\n","    net.barnes_hut(\n","        gravity=-2000,\n","        central_gravity=0.3,\n","        spring_length=200,\n","        spring_strength=0.05,\n","        damping=0.09\n","    )\n","\n","    # Add nodes (bigger, clearer)\n","    for entity in entities:\n","        net.add_node(\n","            entity,\n","            label=entity,\n","            shape=\"ellipse\",\n","            size=25,\n","            color=\"#97c2fc\"\n","        )\n","\n","    # Add edges (IMPORTANT PART)\n","    for src, rel, tgt in edges:\n","        net.add_edge(\n","            src,\n","            tgt,\n","            label=rel,\n","            arrows=\"to\",\n","            font={\"size\": 14, \"align\": \"middle\"},\n","            color=\"#000000\"\n","        )\n","\n","    net.write_html(output_file)\n","    print(f\"Knowledge graph saved to {output_file}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["### Query Retrieval chain "]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:29:06.888586Z","iopub.status.busy":"2026-01-11T10:29:06.887971Z","iopub.status.idle":"2026-01-11T10:29:06.893706Z","shell.execute_reply":"2026-01-11T10:29:06.892844Z","shell.execute_reply.started":"2026-01-11T10:29:06.888560Z"},"trusted":true},"outputs":[],"source":["def generate_answer(question):\n","    cohere_llm = ChatCohere(\n","        model=\"command-xlarge-nightly\",\n","        temperature=0.05,\n","        cohere_api_key=os.getenv(\"cohere_api_key\")\n","    )\n","\n","    # Step 1: Retrieve documents\n","    docs = retriever.get_relevant_documents(question)\n","    context = format_docs(docs)\n","\n","    # Step 2: Extract local KG\n","    kg = extract_kg(docs)\n","\n","    # Step 3: Generate answer using context + KG\n","    answer_prompt = PromptTemplate(\n","        input_variables=[\"context\", \"kg\", \"question\"],\n","        template=prompt_template\n","    )\n","\n","    answer_chain = answer_prompt | cohere_llm | StrOutputParser()\n","\n","    return {\n","        \"answer\": answer_chain.invoke({\n","            \"context\": context,\n","            \"kg\": kg,\n","            \"question\": question\n","        }),\n","        \"knowledge_graph\": kg\n","    }\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2026-01-11T10:30:20.496067Z","iopub.status.busy":"2026-01-11T10:30:20.495714Z","iopub.status.idle":"2026-01-11T10:30:43.569180Z","shell.execute_reply":"2026-01-11T10:30:43.568361Z","shell.execute_reply.started":"2026-01-11T10:30:20.496038Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Answer:\n"," The chapter \"Fibre to Fabric\" explains how fabrics are made from fibres. Hereâ€™s a simple summary:\n","\n","1. **Fibres**: These are the basic units used to make fabrics. Examples of fibres include cotton, silk, wool, and jute. Some fibres come from plants (like cotton and jute), while others come from animals (like silk and wool).\n","\n","2. **Yarn**: Fibres are twisted together to form yarns. This process is called spinning. Yarns are like long threads made from fibres.\n","\n","3. **Fabric**: Yarns are then woven together to make fabrics. Weaving is the process of arranging yarns in a crisscross pattern to create a strong and flexible material.\n","\n","4. **Types of Fabrics**: Different fibres and weaving methods result in different types of fabrics. For example, cotton fibres make soft and breathable fabrics, while wool fibres make warm fabrics.\n","\n","In short, the journey from fibre to fabric involves turning fibres into yarns through spinning and then weaving those yarns into fabrics. This process helps us create the clothes and materials we use every day.\n","\n","Knowledge Graph:\n"," Entities:\n","- Fibres\n","- Fabric\n","- Yarns\n","- Cotton\n","- Silk\n","- Wool\n","- Jute\n","- Weaving\n","\n","Relations:\n","- Fibres -> used for -> Fabric\n","- Yarns -> made up of -> Fibres\n","- Fabric -> made from -> Yarns\n","- Weaving -> process of -> making Fabric\n","- Cotton, Silk, Wool, Jute -> examples of -> Fibres\n","- Fibres -> processed into -> Yarns\n","- Yarns -> woven into -> Fabric\n","Knowledge graph saved to kg.html\n"]}],"source":["result = generate_answer(\"Summarise the full chapter: FIBRE TO FABRIC\")\n","\n","print(\"Answer:\\n\", result[\"answer\"])\n","print(\"\\nKnowledge Graph:\\n\", result[\"knowledge_graph\"])\n","\n","visualize_kg(result[\"knowledge_graph\"])"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":9235278,"sourceId":14459002,"sourceType":"datasetVersion"}],"dockerImageVersionId":31236,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"}},"nbformat":4,"nbformat_minor":4}
